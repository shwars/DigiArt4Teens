{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "# Creating Your Own Cognitive Portrait\n",
        "\n",
        "Hello!\n",
        "\n",
        "We are about to explore **Science Art**, where **Science** - namely **Artificial Intelligence**, part of **Computer Science** - will help us create pieces of **Art**! Namely, we will learn the technique called [Cognitive Portrait](http://bit.do/cognitiveportrait)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/shwars/FaceArt/master/notebooks/img/PhoBoGuy.png\" width=\"30%\"/>\n",
        "\n",
        "In this technique, we use **[Microsoft Face API](https://docs.microsoft.com/azure/cognitive-services/face/overview/?wt.mc_id=digigirlz-event-dmitryso)** to extract **Facial Landmarks** from a series of pictures, and then we scale and align pictures in such a way that eyes on all pictures coincide. Merging those photographs, we create an interesting visual effect, like on the photo above. "
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Using Python and Azure Notebook\n",
        "\n",
        "To create a portrait, we will use a programming language called **Python**. Do not worry, to create your own portrait you do not even need to know programming - you need to execute existing code. But you need to be **very attentive and accurate**.\n",
        "\n",
        "However, if you know programming or want to learn, you would eventually be able to create much more interesting visual effects. The best way to learn Python is by following [this course](http://pythontutor.ru).\n",
        "\n",
        "The document that you see contains **text cells** (you are reading one of them now) **code cells** with Python code - they have `In [..]` printed to the left of the cell. Code cells can be **executed**, by pressing **RUN** button in the toolbar above, or keys **Ctrl-Enter**. After the cell executes, you will see the result directly below it. Try to execute the cell below, where we calculate the number of seconds in a day: "
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "24*60*60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "To create a portrait we need to execute a number of cells with code. You need to do it step by step, sequentially, waiting for the previous cell to finish execution. While cell is being executed, you see `In [*]` to the left of it, and when it is done - star `*` is replaced by a number, showing the order in which the cell has been executed.\n",
        "\n",
        "We are also trying to describe what is happening in each cell. Try to understand it, but if you don't - that's fine. You should be able to get the portrait anyway."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Installing Required Libraries\n",
        "\n",
        "In Python, many complex things are accomplished by using **libraries** - pieces of code that someone else has created for you. For example, to manipulate images we will use **OpenCV** library, and we also need library to use **Microsoft Face API**. To use libraries, we need to:\n",
        "\n",
        "* **install** those libraries, i.e. download their code from the repository where they are stored. This is done using `pip` command. We need to do it once before we start working with a notebook\n",
        "* **import** them into our program, so that Python sees all required functions \n",
        "\n",
        "The following cell will install required libraries. **IMPORTANT**: it can take a few minutes to execute, and you need to wait for it to finish. You may also see a **WARNING** -- do not worry, it is normal."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --quiet opencv-python azure-cognitiveservices-vision-face"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import os, requests, glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Extracting Facial Landmarks\n",
        "\n",
        "To extract facial landmarks, we use [Microsoft Face API](https://azure.microsoft.com/services/cognitive-services/face/?wt.mc_id=digigirlz-event-dmitryso). It will give us a lot of extra useful information, including gender, age, head's angles of rotation, emotions, makeup, accessories. The following facial landmarks are extracted:\n",
        "\n",
        "![Facial Landmarks](https://raw.githubusercontent.com/shwars/FaceArt/master/notebooks/img/landmarks.jpg)\n",
        "\n",
        "To read more about Face API and how to use it from different programming languages, [visit Microsoft Docs](https://docs.microsoft.com/ru-ru/azure/cognitive-services/face/index/?wt.mc_id=digigirlz-event-dmitryso)."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "To use Face API we need a special **key**, and also so-called **Endpoint URL** which is used to call the service. To get it, you need to have **Microsoft Azure Account**, and **Create Cognitive Service** resource there which will give you access information.\n",
        "\n",
        "The easiest ways to get Azure Account are the following:\n",
        "* If you are a student, get [Azure for Students](http://aka.ms/az4stud). You would need to verify your student status via university e-mail account.\n",
        "* You can also apply for [GitHub Student Developer Pack](https://education.github.com/pack) that gives you access to several free resources for student developers, including Azure. You need to verify your status using university e-mail or a supporting document.\n",
        "* Anyone can apply for [Azure Free Trial](http://aka.ms/azfree).\n",
        "\n",
        "Having created your account, you need to create Cognitive Servies recourse through [Azure Portal](http://portal.azure.com/?WT.mc_id=digigirlz-event-dmitryso) as [described here](https://docs.microsoft.com/azure/cognitive-services/cognitive-services-apis-create-account?tabs=multiservice%2Cwindows&WT.mc_id=digigirlz-event-dmitryso) \n",
        "\n",
        "After that, you need to copy one of two provided **keys** (a sequence of numbers) and **endpoint URL** (which looks like internet address) to the cell below: "
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "key = '--INSERT YOUR KEY HERE--' # key looks similar to this: 'e408f9b7c8e349ee8f5567dbea67df30'\n",
        "endpoint = 'https://westus2.api.cognitive.microsoft.com' # please make sure to copy correct endpoint URL as well"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT**: Endpoint URL provided for you on the web site looks like this: `https://westus2.api.cognitive.microsoft.com/api/face/1.0`. You need to remove the trailing part of the address `/api/face/1.0`, and leave just the server address. If you fail to do it, you will get an error."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "If you have copied everything correctly, after executing the following cell you will see the result of processing this photograph:\n",
        "\n",
        "<img src=\"https://2016.dotnext-piter.ru/assets/images/people/soshnikov.jpg\" width=\"20%\"/>"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import azure.cognitiveservices.vision.face as cf\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "cli = cf.FaceClient(endpoint,CognitiveServicesCredentials(key))\n",
        "face_url = 'https://2016.dotnext-piter.ru/assets/images/people/soshnikov.jpg'\n",
        "res = cli.face.detect_with_url(face_url,return_face_landmarks=True)\n",
        "print(res[0].face_landmarks.as_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT**: You should see the coordinates of facial landmarks. If you do not see them - make sure you have copied the keys correctly. You need to make this cell working right, otherwise nothing will work. Go ahead only after you see the facial landmarks with coordinates like this:\n",
        "```\n",
        "{'eye_right_bottom': {'x': 172.7, 'y': 123.5}, 'eye_right_inner': {'x': 162.7, 'y': 120.8}, ... }\n",
        "```"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Uploading Your Own Images\n",
        "\n",
        "For experiments, we need our own portrait pictures. To create your portrait, you need to place a few (5 to 15, but no more than 20) your photographs into `images` directory of this notebook. For your convenience, this directory aleady contains a couple of photographs - feel free to delete them, if you do not want to mix them into the portrait. You can also leave them :)\n",
        "\n",
        "It is best to take pictures that contain only your face in different settings/surroundings. If several faces are detected in one picture, our code will take any one of them, and thus if there are more people it may mix them into the portrait instead of you.\n",
        "\n",
        "To upload images, you need to switch to previous browser tab, which contains all files for our notebook library. Then follow the steps (indicated also by digits in the picture below):\n",
        "\n",
        "1. Go to `images` directory -- list of files should change to reflect a couple of existing pictures\n",
        "2. Press upload button (with arrow) in the right corner and select **Upload from Computer**\n",
        "3. A window will open. Drag the files from explorer/finder on your computer to this window, or press **Choose Files** button and select required files from your computer\n",
        "4. After you do it, you should see the list of files below in the windows\n",
        "5. Place check mark next to **I trust the contents of those files**\n",
        "6. Press **Upload**\n",
        "7. After uploading, the Upload button will change to **Done**, press it once more.\n",
        "\n",
        "|![Upload Screen 1](.img/Upload1.PNG) | ![Upload Screen 2](.img/Upload2.PNG) |\n",
        "| ---| ----|\n"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Once we have uploaded the photographs, let's see how Face API handles them:"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "def imread(fn):\n",
        "    im = cv2.imread(fn)\n",
        "    return cv2.cvtColor(im,cv2.COLOR_BGR2RGB) if im is not None else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "fn = glob.glob('images/*')[0]\n",
        "print('Analyzing image: ',fn)\n",
        "\n",
        "img = imread(fn)\n",
        "cli.face.detect_with_url(face_url)\n",
        "with open(fn,'rb') as f:\n",
        "    res = cli.face.detect_with_stream(f,return_face_landmarks=True)\n",
        "for k,v in res[0].face_landmarks.as_dict().items():\n",
        "    cv2.circle(img,(int(v['x']),int(v['y'])),7,(255,255,0),5)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "If you see an error in the cell above - it probably means that Face API did not find a face on the picture. You should try to use better pictures.\n",
        "\n",
        "For our experiments, let's run all our faces through the Face API to get the landmarks. We will store images into `images` list, and landmarks - into `imagepoints`. \n",
        "\n",
        "**Important**: Trial Face API key allows you to process only 20 requests per minute. Thus, if you want to process more than 20 pictures with trial key, you would need to make code a bit more complex, adding some delay between calls."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "filenames = []\n",
        "images = []\n",
        "imagepoints = []\n",
        "cli.face.detect_with_url(face_url)\n",
        "for fn in glob.glob(\"images/*\")[0:20]:\n",
        "    print(\"Processing image {} \".format(fn),end='')\n",
        "    try:\n",
        "        with open(fn,'rb') as f:\n",
        "            res = cli.face.detect_with_stream(f,return_face_landmarks=True)\n",
        "    except:\n",
        "        print(' - ERROR - ',end='')\n",
        "        res = []\n",
        "    print(' {} faces found'.format(len(res)))\n",
        "    if len(res)>0:\n",
        "        filenames.append(fn)\n",
        "        images.append(imread(fn))\n",
        "        imagepoints.append(res[0].face_landmarks.as_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT**: If you see **ERROR** message, it means that Face API could not understand your photo. It is possible that picture is too big (Face API has some limit on image size), or format is not supported. Try to make the image smaller and upload it again. However, if there are a few errors - it does not matter, those pictures are just ignored, it is important to make sure that we have at least 3-5 faces that were recognized correctly."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Let's see a few of loaded photographs:"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "def display_images(l):\n",
        "    n=len(l)\n",
        "    fig,ax = plt.subplots(1,n)\n",
        "    for i,im in enumerate(l):\n",
        "        ax[i].imshow(im)\n",
        "        ax[i].axis('off')\n",
        "    fig.set_size_inches(fig.get_size_inches()*n)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "display_images(images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Affine Transformations\n",
        "\n",
        "To align all images according to their eyes, we need to scale, move and rotate them in some way. To do that, we use mathematical concept of [**affine transformation**](https://ru.wikipedia.org/wiki/Affine_transformation). You do not need to understand the details, the important thing is to know that we can use some **math magic** to align three given points in an image with any other three points. We will align coordinate of 2 eyes and middle of the mouth with three predefined points.\n",
        "\n",
        "Magic function to do this alignment will look like this:"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "target_triangle = np.float32([[130.0,120.0],[170.0,120.0],[150.0,160.0]])\n",
        "size = 300\n",
        "\n",
        "def affine_transform(img,attrs):\n",
        "    mc_x = (attrs['mouth_left']['x']+attrs['mouth_right']['x'])/2.0\n",
        "    mc_y = (attrs['mouth_left']['y'] + attrs['mouth_right']['y']) / 2.0\n",
        "    tr = cv2.getAffineTransform(np.float32([(attrs['pupil_left']['x'],attrs['pupil_left']['y']),\n",
        "                                            (attrs['pupil_right']['x'],attrs['pupil_right']['y']),\n",
        "                                            (mc_x,mc_y)]), target_triangle)                                \n",
        "    return cv2.warpAffine(img,tr,(size,size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Let's align all photos:"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "img_aligned = [affine_transform(i,a) for i,a in zip(images,imagepoints)]\n",
        "display_images(img_aligned[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Merging the Images\n",
        "\n",
        "To get the result, we need to merge those image together. It is not a difficult task, be we will create powerful merging function that will also allow to set different weights for each image, and to generate random weights. Let's see how first two pictures are mixed together: \n"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "def merge(images,wts=None):\n",
        "    res = np.zeros_like(images[0],dtype=np.float32)\n",
        "    if wts is None:\n",
        "        wts = np.ones(len(images))\n",
        "    wts /= np.sum(wts)\n",
        "    for n,i in enumerate(images):\n",
        "        res += wts[n]*i.astype(np.float32)/255.0\n",
        "    return res\n",
        "\n",
        "display_images([img_aligned[0],img_aligned[1],merge(img_aligned[0:2])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Now let's merge all pictures together, which gives us the cognitive portrait we promised you in the beginning"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "res = merge(img_aligned)\n",
        "plt.imshow(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "You can generate a series of images with random weights, and then select the one you like most:"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "imgs = [merge(img_aligned,np.random.random(len(img_aligned))) for _ in range(5)]\n",
        "display_images(imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Finally, let's save the result into a file. Please run the following cell until you are satisfied with the result - it will produce slightly different image each time:"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "res = merge(img_aligned,np.random.random(len(img_aligned)))\n",
        "plt.imshow(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Now, execute the next cell to save the result to disk:"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "cv2.imwrite('result.jpg',(cv2.cvtColor(res,cv2.COLOR_BGR2RGB)*255.0).astype(np.int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Now you can switch to another browser tab - the one that you used to upload the images. Maybe you need to refresh the page (press **F5**), but you should be able to see `result.jpg` file there. You can download it to your computer and enjoy!\n",
        "\n",
        "Of course, you can also cut an image right from the screen using **Snipping tool** on Windows..."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Learn to Program and Continue Experiments!\n",
        "\n",
        "Hoorah! We learnt how to create simple blended portraits, merging aligned photos together to achieve cool visual effects! You can experiement with different sets of photos:\n",
        "\n",
        "* Use photos of one person at different ages to get \"younger\" photo\n",
        "* Combine pictures of 2 different people or more (take 5 pictures of each one)!\n",
        "* Try to blend many random photos!\n",
        "\n",
        "Bleding photos (which I call **peopleblending**) is only one technique you can use with facial landmarks. You can try different other ways of aligning pictures, for example putting all eyes on a perimeter of a circle, or creating a continuous line of portraits. When you learn Python and OpenCV for image processing, you should be able to create very artistic effects with your code."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Share the Results!\n",
        "\n",
        "I would like to encourage you to share your result, as I have shared this technique with you! As the creator of original **[cognitive portrait](http://bit.do/cognitiveportrait)** technique, I am very curious to see your results. You can [send me the result in a private message](http://fb.com/shwars), but even better - share the reults in social networks using **#cognitiveportrait** hashtag. For example:\n",
        "\n",
        "> Wow, look at the cool #cognitiveportrait I have created this weekend! -- http://bit.do/cognitiveportrait!\n",
        "\n",
        "It would also be nice if you keep the link to the original technique -- http://bit.do/cognitiveportrait -- so that more people can get inspired by it!\n",
        "\n",
        "Don't stop at this, be creative and be happy!!!"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}